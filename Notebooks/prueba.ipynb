{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas.plotting import lag_plot\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import io\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.cm as cm\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "from IPython.display import Image\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import math\n",
    "# Para guardar los modelos entrenados\n",
    "import joblib as joblib\n",
    "# Para crossvalidaci칩n\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictor_lag3_escalado = read_csv('../Datos_preprocesados/predictor_lag3_escalado.csv', encoding='latin-1', sep = ',', na_values = ['NaN', 'NaT'])\n",
    "df_predictor_lag3_escalado = df_predictor_lag3_escalado.set_index('Fecha')\n",
    "df_predictor_lag3_escalado.head(3)\n",
    "\n",
    "df_predictor_lag5_escalado = read_csv('../Datos_preprocesados/predictor_lag5_escalado.csv', encoding='latin-1', sep = ',', na_values = ['NaN', 'NaT'])\n",
    "df_predictor_lag5_escalado = df_predictor_lag5_escalado.set_index('Fecha')\n",
    "df_predictor_lag5_escalado.head(3)\n",
    "\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(df_predictor_lag3_escalado.drop(['Incidentes'], axis=1),\n",
    "                                        df_predictor_lag3_escalado['Incidentes'], train_size = 0.8, test_size = 0.2, \n",
    "                                        random_state = 42, shuffle = False)\n",
    "\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(df_predictor_lag5_escalado.drop(['Incidentes'], axis=1),\n",
    "                                        df_predictor_lag5_escalado['Incidentes'], train_size = 0.8, test_size = 0.2, \n",
    "                                        random_state = 42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "def search_grid(estimador, grid, X_train, y_train):\n",
    "    # Buscamos los mejores hiperparametros\n",
    "    clf = GridSearchCV(estimator=estimador, \n",
    "                        param_grid=grid,\n",
    "                        cv=cv,\n",
    "                        #refit=True,\n",
    "                        #error_score=0,\n",
    "                        # POR DEFECTO -> R^2\n",
    "                        #scoring = miscorer,#'neg_root_mean_squared_error',\n",
    "                        scoring = 'neg_root_mean_squared_error',\n",
    "                        #scoring = miscorer,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5, 7, 10, 15, 20],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 4, 5],\n",
    "    'min_samples_split': [4, 8, 10, 14],\n",
    "    'n_estimators': [100, 300, 500, 1000, 1500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = search_grid(rf, grid, X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-9-049b88a30ed0>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-049b88a30ed0>\"\u001b[1;36m, line \u001b[1;32m31\u001b[0m\n\u001b[1;33m    predicciones = []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def MAE(y_pred, y_test):\n",
    "    mae = round(sm.mean_absolute_error(y_test, y_pred), 2)\n",
    "    print(\"Mean absolute error =\", mae)\n",
    "    return mae\n",
    "\n",
    "def RMSE(y_pred, y_test):\n",
    "    rmse = round(math.sqrt(sm.mean_squared_error(y_test, y_pred)), 2)\n",
    "    print(\"RMSE =\", rmse)\n",
    "    return rmse\n",
    "\n",
    "def grafica(p, t, i):\n",
    "    \n",
    "    plt.style.use('seaborn-darkgrid')  \n",
    "    \n",
    "    pd.Series(p).plot(color = 'forestgreen', linewidth = 1.8, alpha = 0.9, label = 'Incidentes predecidos')\n",
    "    t.plot(color = 'dodgerblue', linewidth = 1.8, alpha = 0.9, label = 'Incidentes Reales') \n",
    "    \n",
    "    titulo = 'Indicentes t+'+str(i+1)\n",
    "    if i+1 == 0:\n",
    "        titulo = 'Incidentes t'  \n",
    "        \n",
    "    plt.title(titulo, loc ='center', fontsize = 12, fontweight = 0, color = 'black')\n",
    "    \n",
    "    plt.legend(loc ='best')\n",
    "\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def calcular_predicciones_lag3(modelo, y_pred, X_test):\n",
    "predicciones = []\n",
    "X_test_modelo = X_test.copy()\n",
    "for i in range(1,8):\n",
    "    # Modificamos el conjunto de test\n",
    "    X_test_modelo['Incidentes t-3'] = X_test_modelo['Incidentes t-2']\n",
    "    X_test_modelo['Incidentes t-2'] = X_test_modelo['Incidentes t-1']\n",
    "    X_test_modelo['Incidentes t-1'] = y_pred\n",
    "    # Predecimos\n",
    "    y_pred = modelo.predict(X_test_modelo)\n",
    "    # Ajustamos al tama침o\n",
    "    pred = y_pred[i:]\n",
    "    predicciones.append(pred)\n",
    "return predicciones\n",
    "\n",
    "def visualizar_predicciones(y_test, predicciones):\n",
    "    \n",
    "    # TODO : CREO NO NECESARIO\n",
    "    #test = y_test.copy()\n",
    "\n",
    "    #palette = plt.get_cmap('prism')\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "    for i in range(1,len(predicciones)+1):\n",
    "        # Tomo la predicci칩n en t+i\n",
    "        s = pd.Series(predicciones[i-1])\n",
    "        # Para mostrarla, la desplazo i valores a la derecha para colocarla en el dia correspondiente de prediccion\n",
    "        s = s.shift(+i)\n",
    "        s.dropna(axis = 0, inplace = True)\n",
    "\n",
    "        s.plot(linewidth = 1.6, alpha = 0.9, label = 'Incidentes predecidos t+'+str(i))\n",
    "        #s.plot(linewidth = 1.6, alpha = 0.9, label = 'Incidentes predecidos t+'+str(i))\n",
    "        \n",
    "        # TODO : CREO NO NECESARIO\n",
    "        #test = test.drop([test.index[0]])\n",
    "\n",
    "    y_test.plot(linewidth = 1.6, alpha = 0.9, label = 'Incidentes Reales') \n",
    "    #y_test.plot(linewidth = 1.6, alpha = 0.9, label = 'Incidentes Reales') \n",
    "\n",
    "    plt.title('Evoluci칩n incidentes', loc ='center', fontsize = 12, fontweight = 0, color = 'black')\n",
    "\n",
    "    #plt.legend(loc='best')\n",
    "    plt.legend(loc = 'center left', bbox_to_anchor = (1, 0.5))\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_rf = clf_rf.best_estimator_\n",
    "\n",
    "clf_rf.best_params_\n",
    "\n",
    "joblib.dump(optimised_rf, 'rf_lag3_prueba.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_rf_lag3 = joblib.load('rf_lag3_prueba.pkl')\n",
    "\n",
    "y_pred = optimised_rf_lag3.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEs_test_lag3_rf = []\n",
    "MAEs_test_lag3_rf = []\n",
    "CCs_test_lag3_rf = []\n",
    "\n",
    "RMSEs_test_lag3_rf.append(RMSE(y_pred, y_test_3))\n",
    "MAEs_test_lag3_rf.append(MAE(y_pred, y_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafica(y_pred, y_test_3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_rf_lag3 = calcular_predicciones_lag3(optimised_rf_lag3, y_pred, X_test_3)\n",
    "\n",
    "visualizar_predicciones(y_test_3, predicciones_rf_lag3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
